{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION AND EXPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import pandas library and read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/survey_results_public.csv', sep=\",\", header=0)\n",
    "print(len(df))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q120 - only one unique value - irrelevant information, checking if there more column like this\n",
    "\n",
    "for column in df:\n",
    "    unique_values = df[column].unique()\n",
    "    if len(unique_values) < 5:\n",
    "        print(f'Column name: {column:20} | unique values: {unique_values}')\n",
    "\n",
    "# SurveyLentgh, SurveyEase - irrelevant information for further analysis\n",
    "\n",
    "cols = [\"Q120\", \"SurveyLength\", \"SurveyEase\"]\n",
    "\n",
    "df.drop(cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Remove duplicate and Incomplete Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows where more than 60% of column values is null\n",
    "n_columns = len(df.columns)\n",
    "# n_incomplete = 0\n",
    "# for row in df.index:\n",
    "#     n_nulls = 0\n",
    "#     for column in df:\n",
    "#         if pd.isnull(df[column][row]):\n",
    "#             n_nulls += 1\n",
    "#     if n_nulls/n_columns > 0.6:\n",
    "#         n_incomplete += 1\n",
    "# print(n_incomplete)\n",
    "\n",
    "# much, much faster way to do so\n",
    "mostly_nulls = df.isnull().sum(axis=1)\n",
    "mostly_nulls_count = mostly_nulls[mostly_nulls/n_columns > 0.6]\n",
    "df.drop(mostly_nulls_count.index, inplace=True)\n",
    "print(f'Removed {len(mostly_nulls_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.iloc[:,1:].duplicated().any()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Threat null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [column for column in df if df[column].isnull().sum()>0 and df[column].dtype == 'object']\n",
    "df = df.fillna(dict.fromkeys(cols, 'NA'))\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Handle data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V. Remove nonsense answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df[df[\"CompTotal\"] > df[\"CompTotal\"].quantile(0.995)]\n",
    "df[\"CompTotal\"].quantile(0.995)\n",
    "display(rows)\n",
    "df.drop(rows, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years should be integers\n",
    "df['WorkExp'] = df['WorkExp'].astype('Int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First approach on CodingActivities\n",
    "not_null_CA = df['CodingActivities'][df['CodingActivities'].notnull()]\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    display(not_null_CA[\n",
    "        (df['CodingActivities'].str.contains('Hobby') != True) &\n",
    "        (df['CodingActivities'].str.contains('Freelance/contract') != True) &\n",
    "        (df['CodingActivities'].str.contains('Contribute to open-source') != True) &\n",
    "        (df['CodingActivities'].str.contains('Bootstrapping a business') != True) &\n",
    "        (df['CodingActivities'].str.contains('School or academic') != True) &\n",
    "        (df['CodingActivities'].str.contains('Professional development') != True) &\n",
    "        (df['CodingActivities'].str.contains('code outside of work') != True)\n",
    "        ].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More gentle approach on LearnCode\n",
    "not_null_LC = df['LearnCode'][df['LearnCode'].notnull()]\n",
    "listed_LC = not_null_CA.str.split(';')\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    # Check if there are user inputs and additionally nonsense answers\n",
    "    display(listed_LC.explode().unique())\n",
    "    \n",
    "    # Check if nonsense answer is repeatable\n",
    "    #display(listed_LC.explode()[listed_CA.explode() == 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LearnCodeOnline\n",
    "not_null_LCO = df['LearnCodeOnline'][df['LearnCodeOnline'].notnull()]\n",
    "listed_LCO = not_null_LCO.str.split(';')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    # Check if there are user inputs and additionally nonsense answers\n",
    "    display(listed_LCO.explode().unique())\n",
    "    \n",
    "     # Check if nonsense answer is repeatable\n",
    "    #display(listed_LC.explode()[listed_CA.explode() == 'Click to write Choice 20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LearnCodeCoursesCert\n",
    "not_null_LCCC = df['LearnCodeCoursesCert'][df['LearnCodeCoursesCert'].notnull()]\n",
    "listed_LCCC = not_null_LCCC.str.split(';')\n",
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    # Check if there are user inputs and additionally nonsense answers\n",
    "    display(listed_LCCC.explode().unique())\n",
    "    \n",
    "     # Check if nonsense answer is repeatable\n",
    "    #display(listed_LCCC.explode()[listed_CA.explode() == 'answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df[\"CompTotal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df['SOAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = {}\n",
    "\n",
    "for column in df:\n",
    "    if df[column].dtype == \"object\":\n",
    "        size_dict[column] = f'string: {df[column].str.len().max()}'\n",
    "    elif df[column].dtype == 'int64' or df[column].dtype == 'float64':\n",
    "        size_dict[column] = f'max_number {df[column].dtype}: {df[column].max()}'\n",
    "    \n",
    "size_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SOAI_len\"] = df[\"SOAI\"].str.len()\n",
    "sorted_soai = df.sort_values(by=\"SOAI_len\", ascending=False)\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(sorted_soai[\"SOAI\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df[df['WorkExp'] == df['WorkExp'].max()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.float_format = '{:.0f}'.format\n",
    "#pd.options.display.float_format = '{:.7e}'.format\n",
    "df['CompTotal'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts, bins = np.histogram(df[\"CompTotal\"])\n",
    "plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with pd.option_context(\"display.max_columns\", None):\n",
    "    display(df[df['WorkExp'] == df[\"WorkExp\"].isnull()].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CompTotal\"].mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
